{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the world a safer place by identifying distracted drivers âœŒ\n",
    "- Using VGG16 pretrained network\n",
    "- Data set : https://www.kaggle.com/c/state-farm-distracted-driver-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download + Unzip Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StateFarm Data Set : https://www.kaggle.com/c/state-farm-distracted-driver-detection\n",
    "- Place unzipped contents in ./data/ folder relative to this notebook's current folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy a small sample of the data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy first 10 images from each category to a sample folder with same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/c0/img_100026.jpg  ->  data/sample/train/c0/img_100026.jpg\n",
      "data/train/c0/img_10003.jpg  ->  data/sample/train/c0/img_10003.jpg\n",
      "data/train/c0/img_100050.jpg  ->  data/sample/train/c0/img_100050.jpg\n",
      "data/train/c0/img_100074.jpg  ->  data/sample/train/c0/img_100074.jpg\n",
      "data/train/c0/img_10012.jpg  ->  data/sample/train/c0/img_10012.jpg\n",
      "data/train/c0/img_100145.jpg  ->  data/sample/train/c0/img_100145.jpg\n",
      "data/train/c0/img_100191.jpg  ->  data/sample/train/c0/img_100191.jpg\n",
      "data/train/c0/img_100257.jpg  ->  data/sample/train/c0/img_100257.jpg\n",
      "data/train/c0/img_100312.jpg  ->  data/sample/train/c0/img_100312.jpg\n",
      "data/train/c0/img_100337.jpg  ->  data/sample/train/c0/img_100337.jpg\n",
      "data/train/c1/img_100021.jpg  ->  data/sample/train/c1/img_100021.jpg\n",
      "data/train/c1/img_100045.jpg  ->  data/sample/train/c1/img_100045.jpg\n",
      "data/train/c1/img_100046.jpg  ->  data/sample/train/c1/img_100046.jpg\n",
      "data/train/c1/img_10011.jpg  ->  data/sample/train/c1/img_10011.jpg\n",
      "data/train/c1/img_100126.jpg  ->  data/sample/train/c1/img_100126.jpg\n",
      "data/train/c1/img_100135.jpg  ->  data/sample/train/c1/img_100135.jpg\n",
      "data/train/c1/img_100153.jpg  ->  data/sample/train/c1/img_100153.jpg\n",
      "data/train/c1/img_100155.jpg  ->  data/sample/train/c1/img_100155.jpg\n",
      "data/train/c1/img_100230.jpg  ->  data/sample/train/c1/img_100230.jpg\n",
      "data/train/c1/img_100348.jpg  ->  data/sample/train/c1/img_100348.jpg\n",
      "data/train/c2/img_100029.jpg  ->  data/sample/train/c2/img_100029.jpg\n",
      "data/train/c2/img_100108.jpg  ->  data/sample/train/c2/img_100108.jpg\n",
      "data/train/c2/img_100113.jpg  ->  data/sample/train/c2/img_100113.jpg\n",
      "data/train/c2/img_100168.jpg  ->  data/sample/train/c2/img_100168.jpg\n",
      "data/train/c2/img_100176.jpg  ->  data/sample/train/c2/img_100176.jpg\n",
      "data/train/c2/img_100242.jpg  ->  data/sample/train/c2/img_100242.jpg\n",
      "data/train/c2/img_100246.jpg  ->  data/sample/train/c2/img_100246.jpg\n",
      "data/train/c2/img_100458.jpg  ->  data/sample/train/c2/img_100458.jpg\n",
      "data/train/c2/img_100471.jpg  ->  data/sample/train/c2/img_100471.jpg\n",
      "data/train/c2/img_10048.jpg  ->  data/sample/train/c2/img_10048.jpg\n",
      "data/train/c3/img_100006.jpg  ->  data/sample/train/c3/img_100006.jpg\n",
      "data/train/c3/img_100041.jpg  ->  data/sample/train/c3/img_100041.jpg\n",
      "data/train/c3/img_100048.jpg  ->  data/sample/train/c3/img_100048.jpg\n",
      "data/train/c3/img_100139.jpg  ->  data/sample/train/c3/img_100139.jpg\n",
      "data/train/c3/img_100281.jpg  ->  data/sample/train/c3/img_100281.jpg\n",
      "data/train/c3/img_100328.jpg  ->  data/sample/train/c3/img_100328.jpg\n",
      "data/train/c3/img_100339.jpg  ->  data/sample/train/c3/img_100339.jpg\n",
      "data/train/c3/img_10034.jpg  ->  data/sample/train/c3/img_10034.jpg\n",
      "data/train/c3/img_100374.jpg  ->  data/sample/train/c3/img_100374.jpg\n",
      "data/train/c3/img_100412.jpg  ->  data/sample/train/c3/img_100412.jpg\n",
      "data/train/c4/img_100225.jpg  ->  data/sample/train/c4/img_100225.jpg\n",
      "data/train/c4/img_10025.jpg  ->  data/sample/train/c4/img_10025.jpg\n",
      "data/train/c4/img_100277.jpg  ->  data/sample/train/c4/img_100277.jpg\n",
      "data/train/c4/img_100297.jpg  ->  data/sample/train/c4/img_100297.jpg\n",
      "data/train/c4/img_100343.jpg  ->  data/sample/train/c4/img_100343.jpg\n",
      "data/train/c4/img_100361.jpg  ->  data/sample/train/c4/img_100361.jpg\n",
      "data/train/c4/img_100371.jpg  ->  data/sample/train/c4/img_100371.jpg\n",
      "data/train/c4/img_100452.jpg  ->  data/sample/train/c4/img_100452.jpg\n",
      "data/train/c4/img_10050.jpg  ->  data/sample/train/c4/img_10050.jpg\n",
      "data/train/c4/img_100529.jpg  ->  data/sample/train/c4/img_100529.jpg\n",
      "data/train/c5/img_10000.jpg  ->  data/sample/train/c5/img_10000.jpg\n",
      "data/train/c5/img_100027.jpg  ->  data/sample/train/c5/img_100027.jpg\n",
      "data/train/c5/img_100061.jpg  ->  data/sample/train/c5/img_100061.jpg\n",
      "data/train/c5/img_100121.jpg  ->  data/sample/train/c5/img_100121.jpg\n",
      "data/train/c5/img_100136.jpg  ->  data/sample/train/c5/img_100136.jpg\n",
      "data/train/c5/img_100152.jpg  ->  data/sample/train/c5/img_100152.jpg\n",
      "data/train/c5/img_100215.jpg  ->  data/sample/train/c5/img_100215.jpg\n",
      "data/train/c5/img_100270.jpg  ->  data/sample/train/c5/img_100270.jpg\n",
      "data/train/c5/img_100309.jpg  ->  data/sample/train/c5/img_100309.jpg\n",
      "data/train/c5/img_100334.jpg  ->  data/sample/train/c5/img_100334.jpg\n",
      "data/train/c6/img_0.jpg  ->  data/sample/train/c6/img_0.jpg\n",
      "data/train/c6/img_100036.jpg  ->  data/sample/train/c6/img_100036.jpg\n",
      "data/train/c6/img_100065.jpg  ->  data/sample/train/c6/img_100065.jpg\n",
      "data/train/c6/img_100109.jpg  ->  data/sample/train/c6/img_100109.jpg\n",
      "data/train/c6/img_100116.jpg  ->  data/sample/train/c6/img_100116.jpg\n",
      "data/train/c6/img_100144.jpg  ->  data/sample/train/c6/img_100144.jpg\n",
      "data/train/c6/img_100181.jpg  ->  data/sample/train/c6/img_100181.jpg\n",
      "data/train/c6/img_100200.jpg  ->  data/sample/train/c6/img_100200.jpg\n",
      "data/train/c6/img_100232.jpg  ->  data/sample/train/c6/img_100232.jpg\n",
      "data/train/c6/img_100241.jpg  ->  data/sample/train/c6/img_100241.jpg\n",
      "data/train/c7/img_100057.jpg  ->  data/sample/train/c7/img_100057.jpg\n",
      "data/train/c7/img_100076.jpg  ->  data/sample/train/c7/img_100076.jpg\n",
      "data/train/c7/img_100164.jpg  ->  data/sample/train/c7/img_100164.jpg\n",
      "data/train/c7/img_100167.jpg  ->  data/sample/train/c7/img_100167.jpg\n",
      "data/train/c7/img_100188.jpg  ->  data/sample/train/c7/img_100188.jpg\n",
      "data/train/c7/img_100201.jpg  ->  data/sample/train/c7/img_100201.jpg\n",
      "data/train/c7/img_100285.jpg  ->  data/sample/train/c7/img_100285.jpg\n",
      "data/train/c7/img_100314.jpg  ->  data/sample/train/c7/img_100314.jpg\n",
      "data/train/c7/img_100336.jpg  ->  data/sample/train/c7/img_100336.jpg\n",
      "data/train/c7/img_100347.jpg  ->  data/sample/train/c7/img_100347.jpg\n",
      "data/train/c8/img_100015.jpg  ->  data/sample/train/c8/img_100015.jpg\n",
      "data/train/c8/img_100235.jpg  ->  data/sample/train/c8/img_100235.jpg\n",
      "data/train/c8/img_100295.jpg  ->  data/sample/train/c8/img_100295.jpg\n",
      "data/train/c8/img_100368.jpg  ->  data/sample/train/c8/img_100368.jpg\n",
      "data/train/c8/img_100446.jpg  ->  data/sample/train/c8/img_100446.jpg\n",
      "data/train/c8/img_100467.jpg  ->  data/sample/train/c8/img_100467.jpg\n",
      "data/train/c8/img_100480.jpg  ->  data/sample/train/c8/img_100480.jpg\n",
      "data/train/c8/img_100515.jpg  ->  data/sample/train/c8/img_100515.jpg\n",
      "data/train/c8/img_100688.jpg  ->  data/sample/train/c8/img_100688.jpg\n",
      "data/train/c8/img_100693.jpg  ->  data/sample/train/c8/img_100693.jpg\n",
      "data/train/c9/img_100090.jpg  ->  data/sample/train/c9/img_100090.jpg\n",
      "data/train/c9/img_100100.jpg  ->  data/sample/train/c9/img_100100.jpg\n",
      "data/train/c9/img_100190.jpg  ->  data/sample/train/c9/img_100190.jpg\n",
      "data/train/c9/img_100286.jpg  ->  data/sample/train/c9/img_100286.jpg\n",
      "data/train/c9/img_100294.jpg  ->  data/sample/train/c9/img_100294.jpg\n",
      "data/train/c9/img_100299.jpg  ->  data/sample/train/c9/img_100299.jpg\n",
      "data/train/c9/img_100327.jpg  ->  data/sample/train/c9/img_100327.jpg\n",
      "data/train/c9/img_100379.jpg  ->  data/sample/train/c9/img_100379.jpg\n",
      "data/train/c9/img_100394.jpg  ->  data/sample/train/c9/img_100394.jpg\n",
      "data/train/c9/img_100428.jpg  ->  data/sample/train/c9/img_100428.jpg\n",
      "data/test//img_1.jpg  ->  data/sample/test//img_1.jpg\n",
      "data/test//img_10.jpg  ->  data/sample/test//img_10.jpg\n",
      "data/test//img_100.jpg  ->  data/sample/test//img_100.jpg\n",
      "data/test//img_1000.jpg  ->  data/sample/test//img_1000.jpg\n",
      "data/test//img_100000.jpg  ->  data/sample/test//img_100000.jpg\n",
      "data/test//img_100001.jpg  ->  data/sample/test//img_100001.jpg\n",
      "data/test//img_100002.jpg  ->  data/sample/test//img_100002.jpg\n",
      "data/test//img_100003.jpg  ->  data/sample/test//img_100003.jpg\n",
      "data/test//img_100004.jpg  ->  data/sample/test//img_100004.jpg\n",
      "data/test//img_100005.jpg  ->  data/sample/test//img_100005.jpg\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "trainRoot, testRoot, sampleRoot = 'data/train/', 'data/test/', 'data/sample/'\n",
    "numFiles = 10\n",
    "\n",
    "def copyNumFiles(srcFolder, destFolder, numFiles):\n",
    "    files = os.listdir(srcFolder)\n",
    "    for file in files[0:numFiles]:\n",
    "        src = srcFolder+'/'+file\n",
    "        dest = destFolder+'/'+file\n",
    "        \n",
    "        if not(os.path.isdir(destFolder)):\n",
    "            os.makedirs(destFolder)\n",
    "        \n",
    "        shutil.copy2(src, dest)\n",
    "        print(src, ' -> ', dest)\n",
    "\n",
    "# Copy Training Data\n",
    "trainFolders = os.listdir(trainRoot)\n",
    "for cur in trainFolders:\n",
    "    copyNumFiles(trainRoot + cur, sampleRoot+'train/'+cur, numFiles)\n",
    "\n",
    "copyNumFiles(testRoot, sampleRoot+'test/', numFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows plots to be displayed right in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use path variable to easily switch between sub-sample (for speed) and full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'data/sample'\n",
    "path = '/media/angus/Windows/Users/mcleana/workspace/machine-learning/FastAI Course/Lesson 1/data/sample/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import / Initialize Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set evironment vars for Theano to run without GPU backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"THEANO_FLAGS\"] = \"device=cuda\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import helper files from FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vgg16.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "vgg16.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "vgg16.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
      "vgg16.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "  model.add(Convolution2D(filters, 3, 3, activation='relu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n",
      "Starting training...\n",
      "Done finetune, starting .fit()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vgg16.py:213: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
      "vgg16.py:213: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=1, epochs=1, validation_steps=100)`\n",
      "  validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0b58cabe9b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done finetune, starting .fit()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done .fit()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/workspace/machine-learning/FastAI-Course/Lesson 1/vgg16.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batches, val_batches, nb_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n\u001b[0;32m--> 213\u001b[0;31m                 validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   2065\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2174\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m                                      str(generator_output))\n\u001b[0;32m-> 2176\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1802\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/angus/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "# Grab a few images at a time for training and validation.\n",
    "# NB: They must be in subdirectories named based on their category\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "\n",
    "# fixes for keras 2 vs keras 1\n",
    "batches.nb_class = batches.num_class\n",
    "batches.nb_sample = batches.samples\n",
    "val_batches.nb_class = batches.num_class\n",
    "val_batches.nb_sample = val_batches.samples\n",
    "\n",
    "print('Starting training...')\n",
    "vgg.finetune(batches)\n",
    "print('Done finetune, starting .fit()')\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "print('Done .fit()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use model to predict images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = vgg.get_batches(path+'valid', batch_size=4)\n",
    "imgs,labels = next(test_batches)\n",
    "plots(imgs, titles=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
